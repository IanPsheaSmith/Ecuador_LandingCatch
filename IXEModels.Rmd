---
title: "IXEModels"
author: "Ian Pshea-Smith"
date: "`r Sys.Date()`"
output: html_document
---


This first chunk is included to modify settings of the RMarkdown File.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



The following three chunks are a series of functions used to visualize the residuals of a count model.
```{r Rootgram Code}
rootogram <- function(object, ...) {
  UseMethod("rootogram")
}

rootogram.default <- function(object, fitted, breaks = NULL,
  style = c("hanging", "standing", "suspended"),
  scale = c("sqrt", "raw"), plot = TRUE,
  width = NULL, xlab = NULL, ylab = NULL, main = NULL, ...)
{
  ## rectangle style
  scale <- match.arg(scale)
  style <- match.arg(style)

  ## default annotation
  if(is.null(xlab)) {
    xlab <- if(is.null(names(dimnames(object)))) {
      deparse(substitute(object))
    } else {
      names(dimnames(object))[1L]
    }
  }
  if(is.null(ylab)) {
    ylab <- if(scale == "raw") "Frequency" else "sqrt(Frequency)" 
  }
  if(is.null(main)) main <- deparse(substitute(fitted))
  
  ## breaks, midpoints, widths
  if(is.null(breaks)) {
    x <- as.numeric(names(object))
    if(length(x) < 1L) x <- 0L:(length(object) - 1L)
    breaks <- (head(x, -1L) + tail(x, -1L))/2
    breaks <- c(2 * head(x, 1L) - head(breaks, 1L), breaks,
      2 * tail(x, 1L) - tail(breaks, 1L))
    if(is.null(width)) width <- 0.9
  } else {
    x <- (head(breaks, -1L) + tail(breaks, -1L))/2
    if(is.null(width)) width <- 1
  }

  ## raw vs. sqrt scale
  if(scale == "sqrt") {
    obsrvd <- sqrt(as.vector(object))
    expctd <- sqrt(as.vector(fitted))
  } else {
    obsrvd <- as.vector(object)
    expctd <- as.vector(fitted)
  }

  ## height/position of rectangles
  y <- if(style == "hanging") expctd - obsrvd else 0
  height <- if(style == "suspended") expctd - obsrvd else obsrvd

  ## collect everything as data.frame
  rval <- data.frame(observed = as.vector(object), expected = as.vector(fitted),
    x = x, y = y, width = diff(breaks) * width, height = height,
    line = expctd)
  attr(rval, "style") <- style
  attr(rval, "scale") <- scale
  attr(rval, "xlab") <- xlab
  attr(rval, "ylab") <- ylab
  attr(rval, "main") <- main
  class(rval) <- c("rootogram", "data.frame")
  
  ## also plot by default
  if(plot) plot(rval, ...)
  
  ## return invisibly
  invisible(rval)
}

c.rootogram <- rbind.rootogram <- function(...)
{
  ## list of rootograms
  rval <- list(...)
  
  ## group sizes
  for(i in seq_along(rval)) {
    if(is.null(rval[[i]]$group)) rval[[i]]$group <- 1L
  }
  n <- lapply(rval, function(r) table(r$group))

  ## labels
  style <- unlist(lapply(rval, function(r) attr(r, "style")))
  scale <- unlist(lapply(rval, function(r) attr(r, "scale")))
  xlab <- unlist(lapply(rval, function(r) attr(r, "xlab")))
  ylab <- unlist(lapply(rval, function(r) attr(r, "ylab")))
  nam <- names(rval)
  main <- if(is.null(nam)) {
    as.vector(sapply(rval, function(r) attr(r, "main")))
  } else {
    make.unique(rep.int(nam, sapply(n, length)))
  }
  n <- unlist(n)

  ## combine and return
  rval <- do.call("rbind.data.frame", rval)
  rval$group <- if(length(n) < 2L) NULL else rep.int(seq_along(n), n)
  attr(rval, "style") <- style
  attr(rval, "scale") <- scale
  attr(rval, "xlab") <- xlab
  attr(rval, "ylab") <- ylab
  attr(rval, "main") <- main
  class(rval) <- c("rootogram", "data.frame")
  return(rval)
}

plot.rootogram <- function(x,
  xlim = NULL, ylim = NULL, xlab = NULL, ylab = NULL, main = NULL,
  border = "black", fill = "lightgray", col = "#B61A51",
  lwd = 2, pch = 19, lty = 1, max = NULL, type = NULL, axes = TRUE, ...)
{
  ## handling of groups
  if(is.null(x$group)) x$group <- 1L
  n <- max(x$group)
  if(is.null(type)) type <- ifelse(any(table(x$group) > 20L), "l", "b")

  ## annotation
  if(is.null(xlab)) xlab <- TRUE
  if(is.null(ylab)) ylab <- TRUE
  if(is.null(main)) main <- TRUE
  xlab <- rep(xlab, length.out = n)
  ylab <- rep(ylab, length.out = n)
  main <- rep(main, length.out = n)
  if(is.logical(xlab)) xlab <- ifelse(xlab, attr(x, "xlab"), "")
  if(is.logical(ylab)) ylab <- ifelse(ylab, attr(x, "ylab"), "")
  if(is.logical(main)) main <- ifelse(main, attr(x, "main"), "")

  ## plotting function
  rootogram1 <- function(d, ...) {
    ## rect elements
    xleft <- d$x - d$width/2
    xright <- d$x + d$width/2
    ybottom <- d$y
    ytop <- d$y + d$height
    j <- unique(d$group)
    
    ## defaults
    if(is.null(xlim)) xlim <- range(c(xleft, xright))
    if(is.null(ylim)) ylim <- range(c(ybottom, ytop, d$line))

    ## draw rootogram
    plot(0, 0, type = "n", xlim = xlim, ylim = ylim,
      xlab = xlab[j], ylab = ylab[j], main = main[j], axes = FALSE, ...)
    if(axes) {
      axis(1)
      axis(2)
    }
    rect(xleft, ybottom, xright, ytop, border = border, col = fill)
    abline(h = 0, col = border)
    lines(d$x, d$line,
      col = col, pch = pch, type = type, lty = lty, lwd = lwd)
   }
   
   ## draw plots
   if(n > 1L) par(mfrow = n2mfrow(n))
   for(i in 1L:n) rootogram1(x[x$group == i, ], ...)
}

rootogram.numeric <- function(object, fitted, breaks = NULL,
  start = NULL, width = NULL, xlab = NULL, ylab = NULL, main = NULL, ...)
{
  ## distribution to be fitted
  dist <- fitted
  if(!is.character(fitted)) fitted <- deparse(substitute(fitted))
  if(substr(fitted, 1L, 1L) != "d") {
    fitted <- match.arg(tolower(fitted),
      c("beta", "cauchy", "chi-squared", "chisquared", "exponential", "f",
        "gamma", "geometric", "log-normal", "lognormal", "logistic", "logseries", 
	"negative binomial", "negbin", "normal", "gaussian", "poisson", "t", "weibull"))
    fitted <- switch(fitted,
      "chisquared" = "chi-squared",
      "lognormal" = "log-normal",
      "negbin" = "negative binomial",
      "gaussian" = "normal",
      fitted)
    if(fitted == "logseries") {
      dist <- function(x, logit, ...) dlogseries(x, plogis(logit), ...)
      if(is.null(start)) start <- list(logit = 0)
    } else {
      if(is.character(dist)) dist <- fitted
    }
  }

  ## labels
  if(is.null(xlab)) xlab <- deparse(substitute(object))
  if(is.null(main)) main <- sprintf('fitdistr(%s, "%s")', deparse(substitute(object)), fitted)

  ## call MASS::fitdistr
  xfit <- suppressWarnings(try(fitdistr(object, dist, start = start), silent = TRUE))
  if(!inherits(xfit, "fitdistr")) stop("could not obtain fitted distribution")

  ## fitted probability distribution function
  pdist <- switch(fitted,
    "beta" = pbeta,
    "cauchy" = pcauchy, 
    "chi-squared" = pchisq,
    "exponential" = pexp,
    "f" = pf, 
    "gamma" = pgamma,
    "geometric" = pgeom,
    "log-normal" = plnorm, 
    "logistic" = plogis,
    "negative binomial" = pnbinom, 
    "normal" = pnorm,
    "poisson" = ppois,
    "t" = function(x, m, s, df) pt((x - m)/s, df),
    "weibull" = pweibull, 
    paste("p", substr(fitted, 2L, nchar(fitted)), sep = ""))
  if(fitted == "logseries") pdist <- function(x, logit, ...) plogseries(x, plogis(logit), ...)
  if(is.character(pdist)) pdist <- try(get(pdist), silent = TRUE)
  if(!is.function(pdist)) stop("invalid specification of fitted distribution")

  ## second argument should be the full parameter vector
  f <- formals(pdist)
  args <- names(f)
  m <- match(names(xfit$estimate), args)
  formals(pdist) <- c(f[c(1, m)], f[-c(1, m)])
  pfun <- function(x, parm, ...) pdist(x, parm, ...)
  l <- length(xfit$estimate)
  if(l > 1L) {
    body(pfun) <- parse(text = paste("pdist(x, ", paste("parm[", 1L:l, "]", collapse = ", "), ", ...)"))
  }

  ## different default breaks for discrete distributions
  if(is.null(breaks)) {
    if(tolower(fitted) %in% c("geometric", "negative binomial", "poisson", "binomial", "logseries")) {
      breaks <- (if(fitted == "logseries") 0L else -1L):max(object) + 0.5
      if(is.null(width)) width <- 0.9
    } else {
      breaks <- "Sturges"
    }
  }

  ## observed and expected frequencies
  xhist <- hist(object, plot = FALSE, breaks = breaks)
  expctd <- xfit$n * (pfun(tail(xhist$breaks, -1L), xfit$estimate) -
    pfun(head(xhist$breaks, -1L), xfit$estimate))

  ## call base rootogram function
  rootogram.default(xhist$counts, expctd, breaks = xhist$breaks,
    xlab = xlab, main = main, width = width, ...)
}

rootogram.zeroinfl <- rootogram.hurdle <- function(object, newdata = NULL,
  max = NULL, xlab = NULL, main = NULL, width = 0.9, ...)
{
  ## observed response
  mt <- terms(object)
  mf <- if(is.null(newdata)) {
    model.frame(object)
  } else {
    model.frame(mt, newdata, na.action = na.omit)
  }
  y <- model.response(mf)
  w <- model.weights(mf)
  if(is.null(w)) w <- rep(1, NROW(y))
  
  ## observed and expected frequencies
  max0 <- if(is.null(max)) max(1.5 * max(y[w > 0]), 20L) else max  
  obsrvd <- as.vector(xtabs(w ~ factor(y, levels = 0L:max0)))
  expctd <- if(is.null(newdata)) {
    colSums(predict(object, type = "prob", at = 0L:max0) * w)
  } else {
    colSums(predict(object, newdata = newdata, type = "prob", at = 0L:max0, na.action = na.omit) * w)
  }

  ## try to guess a good maximum
  if(is.null(max)) {
    max <- if(all(expctd >= 1L)) max0 else max(ceiling(mean(y)), min(which(expctd < 1L)) - 1L)
    max <- min(max, length(expctd) - 1L)
  }

  ## observed and expected frequencies
  obsrvd <- obsrvd[1L:(max + 1L)]
  expctd <- expctd[1L:(max + 1L)]
  
  if(is.null(xlab)) xlab <- as.character(attr(mt, "variables"))[2L]
  if(is.null(main)) main <- deparse(substitute(object))
  rootogram.default(obsrvd, expctd, breaks = -1L:max + 0.5,
    xlab = xlab, main = main, width = width, ...)  
}

rootogram.zerotrunc <- function(object, newdata = NULL,
  max = NULL, xlab = NULL, main = NULL, width = 0.9, ...)
{
  ## observed response
  mt <- terms(object)
  mf <- if(is.null(newdata)) {
    model.frame(object)
  } else {
    model.frame(mt, newdata, na.action = na.omit)
  }
  y <- model.response(mf)
  w <- model.weights(mf)
  if(is.null(w)) w <- rep(1, NROW(y))
  
  ## observed and expected frequencies
  max0 <- if(is.null(max)) max(1.5 * max(y[w > 0]), 20L) else max  
  obsrvd <- as.vector(xtabs(w ~ factor(y, levels = 1L:max0)))
  expctd <- if(is.null(newdata)) {
    colSums(predict(object, type = "prob", at = 1L:max0) * w)
  } else {
    colSums(predict(object, newdata = newdata, type = "prob", at = 1L:max0, na.action = na.omit) * w)
  }

  ## try to guess a good maximum
  if(is.null(max)) {
    max <- if(all(expctd >= 1L)) max0 else max(ceiling(mean(y)), min(which(expctd < 1L)))
    max <- min(max, length(expctd))
  }

  ## observed and expected frequencies
  obsrvd <- obsrvd[1L:max]
  expctd <- expctd[1L:max]
  
  if(is.null(xlab)) xlab <- as.character(attr(mt, "variables"))[2L]
  if(is.null(main)) main <- deparse(substitute(object))
  rootogram.default(obsrvd, expctd, breaks = 0L:max + 0.5,
    xlab = xlab, main = main, width = width, ...)  
}

rootogram.glm <- function(object, newdata = NULL, breaks = NULL,
  max = NULL, xlab = NULL, main = NULL, width = NULL, ...) 
{
  family <- substr(family(object)$family, 1L, 17L)
  if(!(family %in% c("negbin", "Negative Binomial", "poisson", "binomial", "gaussian"))) {
    stop("family currently not supported")
  }
  
  ## observed response
  mt <- terms(object)
  mf <- if(is.null(newdata)) {
    model.frame(object)
  } else {
    model.frame(mt, newdata, na.action = na.omit)
  }
  y <- model.response(mf)
  w <- model.weights(mf)
  if(is.null(w)) w <- rep(1, NROW(y))
  mu <- predict(object, newdata = newdata, type = "response", na.action = na.omit)

  if(family == "gaussian") {
    ## estimated standard deviation (ML)
    s <- sqrt(weighted.mean(residuals(object)^2, w))

    ## breaks
    if(is.null(breaks)) breaks <- "Sturges"
    breaks <- hist(y[w > 0], plot = FALSE, breaks = breaks)$breaks
    obsrvd <- as.vector(xtabs(w ~ cut(y, breaks, include.lowest = TRUE)))

    ## expected frequencies
    p <- matrix(NA, nrow = length(y), ncol = length(breaks) - 1L)
    for(i in 1L:ncol(p)) p[, i] <- pnorm(breaks[i + 1L], mean = mu, sd = s) -
      pnorm(breaks[i], mean = mu, sd = s)
    expctd <- colSums(p * w)
  } else if(family == "binomial") {
    ## successes and failures
    if(NCOL(y) < 2L) y <- cbind(y, 1L - y)

    ## number of attempts
    size <- unique(rowSums(y))
    if(length(size) > 1L) stop("rootogram only applicable to binomial distributions with same size")
    at <- 0L:size
    breaks <- -1L:size + 0.5
    
    ## observed and expected
    obsrvd <- as.vector(xtabs(w ~ factor(y[, 1L], levels = at)))
    p <- matrix(NA, length(mu), length(at))
    for(i in at) p[, i + 1L] <- dbinom(i, prob = mu, size = size)
    expctd <- colSums(p * w)
  } else {
    ## observed frequencies
    max0 <- if(is.null(max)) max(1.5 * max(y[w > 0]), 20L) else max  
    obsrvd <- as.vector(xtabs(w ~ factor(y, levels = 0L:max0)))

    ## expected frequencies
    at <- 0L:max0
    p <- matrix(NA, length(mu), length(at))
    if(family == "poisson") {
      for(i in at) p[, i + 1L] <- dpois(i, lambda = mu)
    } else {
      theta <- object$theta
      if(is.null(theta)) theta <- get(".Theta", environment(family(object)$variance))
      for(i in at) p[, i + 1L] <- dnbinom(i, mu = mu, size = theta)
    }
    expctd <- colSums(p * w)

    ## try to guess a good maximum
    if(is.null(max)) {
      max <- if(all(expctd >= 1L)) max0 else max(ceiling(mean(y)), min(which(expctd < 1L)) - 1L)
      max <- min(max, length(expctd) - 1L)
    }
    breaks <- -1L:max + 0.5

    ## observed and expected frequencies
    obsrvd <- obsrvd[1L:(max + 1L)]
    expctd <- expctd[1L:(max + 1L)]
  }

  if(is.null(xlab)) xlab <- as.character(attr(mt, "variables"))[2L]
  if(is.null(main)) main <- deparse(substitute(object))
  rootogram.default(obsrvd, expctd, breaks = breaks,
    xlab = xlab, main = main,
    width = if(family == "gaussian") 1 else 0.9, ...)  
}

autoplot.rootogram <- function(object,
  colour = c("black", "#B61A51"), fill = "darkgray", size = c(1.2, 4), ...)
{
  ## determine grouping
  class(object) <- "data.frame"
  if(is.null(object$group)) object$group <- 1L
  n <- max(object$group)
  object$group <- factor(object$group, levels = 1L:n, labels = attr(object, "main"))

  ## FIXME: unneeded copies just to avoid warnings in R CMD check
  x <- object$x
  y <- object$y
  width <- object$width
  height <- object$height
  
  ## rectangles and fitted lines
  rval <- ggplot2::ggplot(object, ggplot2::aes(xmin = x - width/2, xmax = x + width/2, ymin = y, ymax = y + height, x = x, y = line)) +
    ggplot2::geom_rect(colour = colour[1L], fill = fill) + ggplot2::geom_line(colour = colour[2L], size = size[1L]) +
    ggplot2::geom_hline(yintercept = 0)
  if(all(table(object$group) <= 20L)) rval <- rval + ggplot2::geom_point(colour = colour[2L], size = size[2L])

  ## grouping (if any)
  if(n > 1L) rval <- rval + ggplot2::facet_grid(group ~ .)
  
  ## annotation
  rval <- rval + ggplot2::xlab(paste(unique(attr(object, "xlab")), collapse = "/")) +
    ggplot2::ylab(paste(unique(attr(object, "ylab")), collapse = "/"))

  ## return with annotation
  rval
}


rootogram.gam <- function(object, newdata = NULL, breaks = NULL,
                          max = NULL, xlab = NULL, main = NULL, width = NULL, ...) 
{
  family <- substr(family(object)$family, 1L, 17L)
  if(!(family %in% c("Negative Binomial", "poisson", "binomial", "gaussian"))) {
    stop("family currently not supported")
  }
  
  ## observed response
  mt <- terms(object)
  mf <- if(is.null(newdata)) {
    model.frame(object)
  } else {
    model.frame(mt, newdata, na.action = na.omit)
  }
  y <- model.response(mf)
  mu <- predict(object, newdata = object$model, type = "response", na.action = na.omit)
  
  if(family == "gaussian") {
    ## estimated standard deviation (ML)
    s <- sqrt(mean(residuals(object)^2))
    
    ## breaks
    if(is.null(breaks)) breaks <- "Sturges"
    yhist <- hist(y, plot = FALSE, breaks = breaks)
    breaks <- yhist$breaks
    obsrvd <- yhist$count
    
    ## expected frequencies
    p <- matrix(NA, nrow = length(y), ncol = length(breaks) - 1L)
    for(i in 1L:ncol(p)) p[, i] <- pnorm(yhist$breaks[i + 1L], mean = mu, sd = s) -
      pnorm(yhist$breaks[i], mean = mu, sd = s)
    expctd <- colSums(p)
  } else if(family == "binomial") {
    ## successes and failures
    if(NCOL(y) < 2L) y <- cbind(y, 1L - y)
    
    ## number of attempts
    size <- unique(rowSums(y))
    if(length(size) > 1L) stop("rootogram only applicable to binomial distributions with same size")
    at <- 0L:size
    breaks <- -1L:size + 0.5
    
    ## observed and expected
    obsrvd <- table(factor(y[, 1L], levels = at))
    p <- matrix(NA, length(mu), length(at))
    for(i in at) p[, i + 1L] <- dbinom(i, prob = mu, size = size)
    expctd <- colSums(p)
  } else {
    ## observed frequencies
    max0 <- if(is.null(max)) max(1.5 * max(y), 20L) else max  
    obsrvd <- table(factor(y, levels = 0L:max0))
    
    ## expected frequencies
    at <- 0L:max0
    p <- matrix(NA, length(mu), length(at))
    if(family == "poisson") {
      for(i in at) p[, i + 1L] <- dpois(i, lambda = mu)
    } else {
      theta <- object$theta
      if(is.null(theta)) {
          theta <- if (inherits(family(object), "extended.family")) { # family = nb
              ## for nb, theta is on log scale; transform
              family(object)$getTheta(trans = TRUE)
          } else {                                                    # family = negbin
              family(object)$getTheta()
          }
      }
      for(i in at) p[, i + 1L] <- dnbinom(i, mu = mu, size = theta)
    }
    expctd <- colSums(p)
    
    ## try to guess a good maximum
    if(is.null(max)) {
      max <- if(all(expctd >= 1L)) max0 else max(ceiling(mean(y)), min(which(expctd < 1L)) - 1L)
      max <- min(max, length(expctd) - 1L)
    }
    breaks <- -1L:max + 0.5
    
    ## observed and expected frequencies
    obsrvd <- obsrvd[1L:(max + 1L)]
    expctd <- expctd[1L:(max + 1L)]
  }
  
  if(is.null(xlab)) xlab <- as.character(attr(mt, "variables"))[2L]
  if(is.null(main)) main <- deparse(substitute(object))
  rootogram.default(obsrvd, expctd, breaks = breaks,
                    xlab = xlab, main = main,
                    width = if(family == "gaussian") 1 else 0.9, ...)  
}

"+.rootogram" <- function(e1, e2) {
  style <- unique(c(attr(e1, "style"), attr(e2, "style")))
  if(length(style) > 1L) {
    warning(sprintf("different styles (%s != %s) had been used, result now uses style = %s",
      style[1L], style[2L], style[1L]))
    style <- style[1L]
  }
  scale <- unique(c(attr(e1, "scale"), attr(e2, "scale")))
  if(length(scale) > 1L) {
    warning(sprintf("different scales (%s != %s) had been used, result now uses scale = %s",
      scale[1L], scale[2L], scale[1L]))
    scale <- scale[1L]
  }

  ylab <- attr(e1, "ylab")
  xlab <- paste(unique(c(attr(e1, "xlab"), attr(e2, "xlab"))), collapse = " / ")
  main <- paste(unique(c(attr(e1, "main"), attr(e2, "main"))), collapse = " / ")
  e1 <- as.data.frame(e1)
  e2 <- as.data.frame(e2)
  e <- e1[e1$x %in% e2$x, ] + e2[e2$x %in% e1$x, ]
  rootogram.default(structure(e$observed, .Names = e$x/2), e$expected,
    style = style, scale = scale,
    main = main, xlab = xlab, ylab = ylab, plot = FALSE)
}

```
```{r qresiduals Code}
qresiduals <- function(object, ...) {
  UseMethod("qresiduals")
}

qresiduals.default <- function(object, type = c("random", "quantile"), nsim = 1L, prob = 0.5, ...)
{
  ## type of residual for discrete distribution (if any)
  type <- match.arg(type)

  ## if 'object' is not a vector/matrix, apply pit() method
  if(is.object(object) | !is.numeric(object)) {
    object <- try(pit(object))
    if(inherits(object, "try-error")) stop("could not obtain probability integral transform from 'object'")
  }

  ## preprocess supplied probabilities
  nc <- NCOL(object)
  nr <- NROW(object)
  if(nc > 2L) stop("quantiles must either be 1- or 2-dimensional")
  if(nc == 2L) {
    if(type == "random") {
      object <- matrix(
        runif(nr * nsim, min = rep(object[, 1L], nsim), max = rep(object[, 2L], nsim)),
        nrow = nr, ncol = nsim, dimnames = list(rownames(object), paste("r", 1L:nsim, sep = "_"))
      )
    } else {
      nam <- rownames(object)
      object <- object[, 1L]  %*% t(1 - prob) + object[, 2L] %*% t(prob)
      dimnames(object) <- list(nam, paste("q", prob, sep = "_"))
    }
    nc <- NCOL(object)
  }
  if(!is.null(dim(object)) & nc == 1L) object <- drop(object)

  ## compute quantile residuals  
  qnorm(object)
}

pit <- function(object, ...) {
  UseMethod("pit")
}

pit.lm <- function(object, ...)
{
  ## obtain preprocessed response and fitted means
  y <- if(!is.null(object$y)) object$y else model.response(model.frame(object))
  mu <- fitted(object)
  
  ## compute probabilities from response distribution
  pr <- pnorm(y, mean = mu, sd = summary(object)$sigma)
  return(pr)
}

pit.glm <- function(object, ...)
{
  ## obtain preprocessed response and fitted means
  y <- if(!is.null(object$y)) object$y else model.response(model.frame(object))
  weights <- weights(object)
  nobs <- nobs(object)
  etastart <- NULL
  mustart <- NULL
  n <- NULL
  eval(object$family$initialize)
  mu <- fitted(object)
  
  ## compute probabilities from response distribution
  pr <- switch(object$family$family,
    "gaussian" = {
      pnorm(y, mean = mu, sd = sqrt(sum((y - mu)^2) / df.residual(object)))
    },
    "poisson" = {
      cbind(ppois(y - 1L, lambda = mu), ppois(y, lambda = mu))
    },
    "binomial" = {
      y <- y * weights / n
      if(!isTRUE(all.equal(as.numeric(y), as.numeric(round(y))))) {
        stop("binomial quantile residuals require integer response")
      }
      y <- round(y)
      cbind(pbinom(y - 1L, size = n, prob = mu), pbinom(y, size = n, prob = mu))
    },
    stop("not implemented yet")
  )
  return(pr)
}

pit.negbin <- function(object, ...)
{
  ## response and fitted means
  y <- if(!is.null(object$y)) object$y else model.response(model.frame(object))
  mu <- fitted(object)
  
  ## probabilities from response distribution
  pr <- cbind(pnbinom(y - 1L, mu = mu, size = object$theta), pnbinom(y, mu = mu, size = object$theta))  
  return(pr)
}

pit.zeroinfl <- pit.hurdle <- function(object, ...)
{
  ## response
  y <- if(!is.null(object$y)) object$y else model.response(model.frame(object))
  n <- length(y)
  
  ## corresponding probabilities
  pr <- predict(object, type = "prob", max = max(y))
  pr <- cbind(0, t(apply(pr, 1L, cumsum)))
  pr <- cbind(pr[cbind(1L:n, y + 1L)], pr[cbind(1L:n, y + 2L)])
  return(pr)
}

pit.zerotrunc <- function(object, ...)
{
  ## response
  y <- if(!is.null(object$y)) object$y else model.response(model.frame(object))
  n <- length(y)
  
  ## corresponding probabilities
  pr <- predict(object, type = "prob", max = max(y))
  pr <- cbind(0, t(apply(pr, 1L, cumsum)))
  pr <- cbind(pr[cbind(1L:n, y)], pr[cbind(1L:n, y + 1L)])
  return(pr)
}
```
```{r Count Model Autoplot Function Code}
###############################################################################
                    # Count Model Autoplot Function #
###############################################################################

autoplot.countreg <- function(object, legend.position="left"){
  
  ###########
  # rootogram
  
  rootogram.plot <- rootogram(object, style = "hanging", plot = FALSE)
  
  g1 <- autoplot(rootogram.plot) +
    labs(x=all.vars(object$formula)[1], y=expression(sqrt(Frequency)))
  #labs(x="Counts", y=expression(sqrt(Frequency)))
  
  
  
  #########
  # qq plot
  
  qres <- qresiduals(object)
  q2q <- function(y) qnorm(ppoints(length(y)))[order(order(y))]
  qnor <- q2q(qres)
  
  plot.res <- data.frame(theoretical=qnor, residuals=qres)
  
  g2 <- ggplot(plot.res, aes(x=theoretical, y=residuals)) +
    geom_point() +
    labs(x="Theoretical Quantiles", y="Quantile Residuals") +
    geom_abline(slope=1, intercept = 0, lty="dashed")
  
  
  
  ############################
  # expected and actual counts
  
  expected.observed <- rootogram(object, style = "hanging", plot = FALSE)
  
  expected.observed <- data.frame(x=rep(expected.observed$x, 2),
                                  y=c(expected.observed$observed, expected.observed$expected),
                                  group=factor(c(rep("Observed", length(expected.observed$observed)), rep("Expected", length(expected.observed$expected))), levels=c("Observed", "Expected")))
  
  
  # legend justification and position
  
  jus <- c(1, 1)
  pos <- c(0.95, 0.95)
  if (legend.position=="left"){
    jus <- c(0, 1)
    pos <- c(0.05, 0.95)
  }
  
  g3 <- ggplot(expected.observed[expected.observed$x <= 20, ], aes(x=x, y=y, fill=group)) +
    geom_col(position = "dodge") +
    labs(x="Counts", y="Frequency", fill="") +
    scale_fill_grey() +
    theme(legend.justification=jus, legend.position=pos, legend.background=element_blank())
  
  ####################################
  # pearson residuals vs fitted values
  
  g4 <- ggplot(data.frame(x=object$fitted.values, 
                          y=residuals(object, type="pearson")), 
               aes(x=x, y=y)) +
    geom_point() +
    labs(x="Fitted Values", y="Pearson Residuals")
  
  # combine all plots in one grid
  
  gridExtra::grid.arrange(g1, g2, g3, g4)
  
}

```




This chunk is used to import and modify the dataset used for this analysis.
```{r Import IXE.Models}

# === DATA IMPORT AND CLEANING === #

  # Import the prepared dataset with specified column types
    # Contains columns for all variables of importance
      IXE.Models <- read_excel("IXEModels.xlsx", 
          col_types = c("numeric", "text", "date", 
              "text", "text", "numeric", "text", 
              "text", "numeric", "numeric", "numeric", 
              "numeric", "numeric", "numeric", 
              "numeric", "numeric", "numeric", 
              "numeric", "numeric", "numeric", 
              "numeric", "numeric", "numeric", 
              "numeric", "numeric", "numeric", 
              "numeric", "numeric", "numeric", 
              "numeric", "numeric", "numeric", 
              "numeric", "numeric", "numeric", 
              "numeric", "numeric"))
  
  # View imported dataset
    str(IXE.Models)
    head(IXE.Models)
    View(IXE.Models)
  
  # Remove observations with non-standard collection periods
    # Removes periods: "10:00-11:00", "15:00-16:00", "9:00-10:00"
      IXE.Models <- IXE.Models[!IXE.Models$Periodo %in% c("10:00-11:00", "15:00-16:00", "9:00-10:00"), ]
  
  # Create binary (presence/absence) variables for key mosquito species
    IXE.Models$biAeae <- ifelse(IXE.Models$Aeae >= 1, 1, 0)  # Binary Ae. aegypti
    IXE.Models$biCxq <- ifelse(IXE.Models$Cxq >= 1, 1, 0)    # Binary Cx. quinquefasciatus
  
  # View updated dataset
    View(IXE.Models)
```



A list of variable descriptions is added below.
  # ID = ID token/unique identifier for each observation
  # Loc = Location code (B = Borbon, SM = Santa Maria)
  # Fecha = Date of collection
  # Mes = Month name (abbreviated)
  # Periodo = Time period of collection - "05:00-06:00"
  # Hora = Hour of collection (24hr format; "5") 
  # TimeofDay = Period of day (Morning, Afternoon, Evening)
  # Met = Collection method (HDN = Indoor, HLC = Outdoor - see manuscript)
  # MTemp = Mean temperature (°C)
  # MHum = Mean humidity (%)
  # Vien = Wind speed (m/s)
  # Rain = Daily rainfall (mm)
  # Rain3DMA = 3-day moving average of rainfall
  # Rain7DMA = 7-day moving average of rainfall
  # Rain14DMA = 14-day moving average of rainfall
  # Rain3DSum = 3-day sum of rainfall
  # Rain7DSum = 7-day sum of rainfall
  # Rain14DSum = 14-day sum of rainfall
  # Feb = February indicator (0/1)
  # Jan = January indicator (0/1)
  # Mar = March indicator (0/1)
  # Apr = April indicator (0/1)
  # May = May indicator (0/1)
  # Jun = June indicator (0/1)
  # Jul_21 = July 2021 indicator (0/1)
  # Jul_22 = July 2022 indicator (0/1)
  # Aug = August indicator (0/1)
  # Sep = September indicator (0/1)
  # Oct = October indicator (0/1)
  # Nov = November indicator (0/1)
  # Dec = December indicator (0/1)
  # Aeae = Aedes aegypti count
  # Cxq = Culex quinquefasciatus count
  # TotMosq = Total mosquito count
  # NonAeae = Non-Aedes aegypti count
  # NonCxq = Non-Culex quinquefasciatus count
  # Diverse = Species diversity (number of unique species)
  # biAeae = Binary Aedes aegypti presence (0/1)
  # biCxq = Binary Culex quinquefasciatus presence (0/1)
  # Year_Month = Year and month (YYYY-MM format)
  # Year_Month_Date = First day of month as date format
  
  
  
The chunk below was used to make some preliminary graphics  
```{r Visualizations for key variables}    

# === REQUIRED LIBRARIES === #
  library(ggplot2)    # Used for: ggplot(), geom_bar(), geom_line(), geom_point(), geom_text(), theme_minimal(), labs()
  library(dplyr)      # Used for: %>%, group_by(), summarise(), mutate()
  library(FSA)        # Used for: Statistical analysis functions (none explicitly shown in this code)
  library(ggpubr)     # Used for: Publication-ready plots (none explicitly shown in this code)
  library(ggsignif)   # Used for: Adding significance levels to plots (none explicitly shown in this code)

# === AEDES AEGYPTI VISUALIZATION === #
  # Calculate total Ae. aegypti counts for each time period
    aeae_periodo <- IXE.Models %>%
        group_by(Periodo) %>%
        summarise(Total_Aeae = sum(Aeae, na.rm = TRUE))
  
  # Create bar plot of Ae. aegypti counts by time period
    ggplot(aeae_periodo, aes(x = Periodo, y = Total_Aeae)) +
        geom_bar(stat = "identity", fill = "steelblue") +
        labs(
            title = "Total Aedes aegypti Counts by Hourly Period",
            x = "Hourly Period",
            y = "Total Counts"
        ) +
        theme_minimal()

# === RAINFALL ANALYSIS WITH DATE FORMATTING === #
  # Add Year-Month variable and convert to proper Date format
    IXE.Models <- IXE.Models %>%
        mutate(
            Year_Month = format(Fecha, "%Y-%m"),  # Creates YYYY-MM format as character
            Year_Month_Date = as.Date(paste0(Year_Month, "-01"))  # Convert to Date format using first day of month
        )
  
  # Calculate monthly rainfall totals with proper date format
    rain_summary <- IXE.Models %>%
        group_by(Year_Month_Date) %>%  # Use the new Date format column
        summarize(
            Total_Rain = sum(Rain, na.rm = TRUE),
            .groups = "drop"
        )
  
  # Bar plot remains the same but uses Year_Month_Date
    ggplot(rain_summary, aes(x = Year_Month_Date, y = Total_Rain)) +
        geom_bar(stat = "identity", fill = "dodgerblue") +
        geom_text(aes(label = round(Total_Rain, 1)), vjust = -0.5, size = 3.5) +
        labs(
            title = "Monthly Total Rainfall",
            x = "Month",
            y = "Total Rain (mm)"
        ) +
        theme_minimal() +
        theme(
            axis.text.x = element_text(angle = 45, hjust = 1)
        )
  
  # Line plot with corrected date format
    ggplot(rain_summary, aes(x = Year_Month_Date, y = Total_Rain, group = 1)) +
        geom_line(color = "dodgerblue", linewidth = 1) +
        geom_point(color = "dodgerblue", size = 2) +
        geom_text(aes(label = round(Total_Rain, 1)), vjust = -1, size = 3) +
        scale_x_date(
            date_breaks = "1 month",    # Show monthly breaks on x-axis
            date_labels = "%b %Y"       # Format as "Month Year"
        ) +
        labs(
            title = "Monthly Total Rainfall",
            x = "Month",
            y = "Total Rain (mm)"
        ) +
        theme_minimal() +
        theme(
            axis.text.x = element_text(angle = 45, hjust = 1)
        )
```



The subsequent two chunks were used to calculate Wilcoxon Rank-Sum tests comparing
the distributions of two variables.
```{r Wilcoxons for Method & Location}

  library(dplyr)

  # Function to perform Wilcoxon Rank-Sum tests and calculate summaries
    perform_tests_and_summaries <- function(data, var, loc_var, met_var) {
      results <- list()
      
      # Wilcoxon tests
      results$wilcox_loc <- wilcox.test(data[[var]] ~ data[[loc_var]])
      results$wilcox_met <- wilcox.test(data[[var]] ~ data[[met_var]])
    
      # Medians and means by location
      results$median_loc <- aggregate(data[[var]] ~ data[[loc_var]], data, median)
      results$mean_loc <- aggregate(data[[var]] ~ data[[loc_var]], data, mean)
    
      # Medians and means by method
      results$median_met <- aggregate(data[[var]] ~ data[[met_var]], data, median)
      results$mean_met <- aggregate(data[[var]] ~ data[[met_var]], data, mean)
    
      return(results)
    }
    
  # Function to calculate sums by location and method
    calculate_sums <- function(data, var, loc_var, met_var) {
      results <- list()
    
      # Sums by location
      results$sum_loc <- aggregate(data[[var]] ~ data[[loc_var]], data, sum)
    
      # Sums by method
      results$sum_met <- aggregate(data[[var]] ~ data[[met_var]], data, sum)
    
      return(results)
    }


  # List of variables
    variables <- c("MTemp", "MHum", "Vien", "Rain", "Diverse", "Aeae", "Cxq", "TotMosq")
    sumvariables <- c("Cxq", "Aeae", "TotMosq")
    all_results <- list()
    all_sums <- list()
  
  # Loop through each variable and perform the tests and summaries
    for (var in variables) {
      all_results[[var]] <- perform_tests_and_summaries(IXE.Models, var, "Loc", "Met")
    }
    
    for (var in sumvariables) {
      all_sums[[var]] <- calculate_sums(IXE.Models, var, "Loc", "Met")
    }
  
  # Function to print results in a clear format
    # Wilcoxons, means and medians
      print_results <- function(results, var) {
        cat("Results for", var, "\n")
        
        cat("\nWilcoxon Rank-Sum Test by Location (Loc):\n")
        print(results$wilcox_loc)
        
        cat("\nWilcoxon Rank-Sum Test by Method (Met):\n")
        print(results$wilcox_met)
        
        cat("\nMedians by Location:\n")
        print(results$median_loc)
        
        cat("\nMeans by Location:\n")
        print(results$mean_loc)
        
        cat("\nMedians by Method:\n")
        print(results$median_met)
        
        cat("\nMeans by Method:\n")
        print(results$mean_met)
        
        cat("\n----------------------------------------\n")
      }

    # Sums    
      print_sums <- function(results, var) {
        cat("Sums for", var, "\n")
        
        cat("\nSums by Location:\n")
        print(results$sum_loc)
        
        cat("\nSums by Method:\n")
        print(results$sum_met)
        
        cat("\n----------------------------------------\n")
      }
  
    for (var in variables) {
      print_results(all_results[[var]], var)
      print_sums(all_sums[[var]], var)
    }

```



```{r Wilcoxons for biAeae & biCxq}
  
  # Function to perform Wilcoxon Rank-Sum tests and calculate summaries
    perform_tests_and_summaries_binary <- function(data, var, binary_var1, binary_var2) {
      results <- list()
      
    # Wilcoxon tests
      results$wilcox_binary1 <- wilcox.test(data[[var]] ~ data[[binary_var1]])
      results$wilcox_binary2 <- wilcox.test(data[[var]] ~ data[[binary_var2]])
  
    # Medians and means by binary variable 1
      results$median_binary1 <- aggregate(data[[var]] ~ data[[binary_var1]], data, median)
      results$mean_binary1 <- aggregate(data[[var]] ~ data[[binary_var1]], data, mean)
  
    # Medians and means by binary variable 2
      results$median_binary2 <- aggregate(data[[var]] ~ data[[binary_var2]], data, median)
      results$mean_binary2 <- aggregate(data[[var]] ~ data[[binary_var2]], data, mean)
    
    return(results)
  }
  
  # List of variables to test
   variables <- c("MTemp", "MHum", "Vien", "Rain", "Diverse")
  
  # Initialize list to store results for each variable
    all_results_binary <- list()
  
  # Loop through each variable and perform the tests and summaries
    for (var in variables) {
      all_results_binary[[var]] <- perform_tests_and_summaries_binary(IXE.Models, var, "biAeae", "biCxq")
    }
  
  # Function to print results in a clear format
    print_results_binary <- function(results, var) {
      cat("Results for", var, "\n")
      
      cat("\nWilcoxon Rank-Sum Test by biAeae (0/≥1):\n")
      print(results$wilcox_binary1)
      
      cat("\nWilcoxon Rank-Sum Test by biCxq (0/≥1):\n")
      print(results$wilcox_binary2)
      
      cat("\nMedians by biAeae (0/≥1):\n")
      print(results$median_binary1)
      
      cat("\nMeans by biAeae (0/≥1):\n")
      print(results$mean_binary1)
      
      cat("\nMedians by biCxq (0/≥1):\n")
      print(results$median_binary2)
      
      cat("\nMeans by biCxq (0/≥1):\n")
      print(results$mean_binary2)
      
      cat("\n----------------------------------------\n")
    }
    
  # Print results for each variable
    for (var in variables) {
      print_results_binary(all_results_binary[[var]], var)
    }
```



This chunk was used to dredge the hurdle model for Cxq. 
```{r Cxq Initial Model Selection}

  # Libraries
    library(MuMIn) # pdredge()
    library(countreg) # hurdle()
    library(parallel) # clusterExport()
    library(ggfortify) # autoplot

  # Cxq Model - Hurdle
    IXE.Cxq <- hurdle(Cxq ~ as.factor(Met) +as.factor(Loc) + as.factor(Periodo) + as.factor(Mes) +  MTemp + MHum + Vien + Rain + TotMosq + Diverse | as.factor(Met) +as.factor(Loc) + as.factor(Periodo) + as.factor(Mes) +  MTemp + MHum + Vien + Rain + Diverse, dist = "negbin", data = IXE.Models)

###########################################################################################################    
###########################################################################################################    
###########################################################################################################    
   
  # Cxq Model - zero/logistic      
    IXE.Cxq.zero.div <- glm(biCxq ~ as.factor(Met) +as.factor(Loc) + as.factor(Periodo) + as.factor(Mes) +  MTemp + MHum + Vien + Rain + Diverse, family = binomial(link = "logit"), data = IXE.Models)

  # Cxq Model - zero trunc        
    IXE.Models$Cxq0trunc <- IXE.Models$Cxq
    IXE.Models$Cxq0trunc[IXE.Models$Cxq0trunc == 0] <- NA
      IXE.Models.0Trunc <- na.omit(IXE.Models)
    
    IXE.Cxq.zerotrunc.div <- zerotrunc(Cxq0trunc ~ as.factor(Met) + as.factor(Loc) + as.factor(Periodo) + as.factor(Mes) +  MTemp + MHum + Vien + Rain + Diverse, dist = "negbin", data = IXE.Models.0Trunc)
    
  # Set the NA action to fail to ensure complete cases
    options(na.action = "na.fail")
  
  # Create a cluster for parallel processing
    cl <- makeCluster(detectCores() - 1)
    clusterEvalQ(cl, {
      library(MuMIn)
      library(countreg)
      library(parallel)
    })
    clusterExport(cl, list("IXE.Cxq.zero.div", "IXE.Cxq.zerotrunc.div", "IXE.Models", "IXE.Models.0Trunc"))
  
  # Perform the dredge operation with parallel processing for both models
    dredge.IXE.Cxq.zero.div <- dredge(IXE.Cxq.zero.div, cluster = cl, trace = TRUE)
    dredge.IXE.Cxq.count.div <- dredge(IXE.Cxq.zerotrunc.div, cluster = cl, trace = TRUE)    
  
  # Stop the cluster after dredging
    stopCluster(cl)
  
  # Reset the NA action to omit missing values
    options(na.action = "na.omit")
  
  # Summary of the best models (based on AICc by default)
    zero.cxq.dredged.div <- get.models(dredge.IXE.Cxq.zero.div, 1)[[1]]
      summary(zero.cxq.dredged.div)
      vif(zero.cxq.dredged.div)
    
    count.cxq.dredged.div <- get.models(dredge.IXE.Cxq.count.div, 1)[[1]]
      summary(count.cxq.dredged.div)
      vif(count.cxq.dredged.div)
      
      AIC(count.cxq.dredged.div)

  # Additional Dredgings w/ interactions
      IXE.Cxq.zero.ints <- glm(biCxq ~ as.factor(Met) +as.factor(Loc) + as.factor(Periodo) + as.factor(Mes) + MTemp + MHum + Vien + Rain + Diverse + as.factor(Mes)*Rain, family = binomial(link = "logit"), data = IXE.Models)
      
      dredge.IXE.Cxq.zero.ints <- dredge(IXE.Cxq.zero.ints, trace = TRUE)
      zero.cxq.dredged.ints <- get.models(dredge.IXE.Cxq.zero.ints, 1)[[1]]
      summary(zero.cxq.dredged.ints)
      
           
  # Final Hurdle Model based on Dredge
    Hurdle.CxQ.Dredged <- hurdle(
    formula = Cxq ~ as.factor(Loc) + as.factor(Mes) + as.factor(Met) + as.factor(Periodo) + Diverse + MHum | as.factor(Loc) + as.factor(Mes) + as.factor(Met) + as.factor(Periodo) + Diverse + MHum, 
    data = IXE.Models, dist = "negbin")
    summary(Hurdle.CxQ.Dredged)
    AIC(Hurdle.CxQ.Dredged)
    autoplot.countreg(Hurdle.CxQ.Dredged)
    


```



This chunk was used to dredge the binomial model for Aedes aegypti.
```{r Aeae Initial Binary Model Selection}
  # Libraries
    library(MuMIn) # pdredge()
    library(parallel) # clusterExport()

  # Logistic regression   
    IXE.biAeae <- glm(biAeae ~ as.factor(Loc) + as.factor(Mes) + as.factor(Periodo) + as.factor(Met) + MTemp + MHum + Vien + Rain + Diverse, family = binomial(link = "logit"), data = IXE.Models)
    
  # Set the NA action to fail to ensure complete cases
    options(na.action = "na.fail")
  
  # Create a cluster for parallel processing
    cl <- makeCluster(detectCores() - 1)
    clusterEvalQ(cl, {
      library(MuMIn)
      library(countreg)
    })
    clusterExport(cl, list("IXE.biAeae", "IXE.Models"))
  
  # Perform the dredge operation with parallel processing for both models
    dredge.IXE.biAeae <- dredge(IXE.biAeae, cluster = cl, trace = TRUE)
  
  # Stop the cluster after dredging
    stopCluster(cl)
  
  # Reset the NA action to omit missing values
    options(na.action = "na.omit")
  
  # Summary of the best model (based on AICc by default)
    summary(get.models(dredge.IXE.biAeae, 1)[[1]])
    
  # Final Model
    IXE.biAeae.Dredged <- glm(biAeae ~ as.factor(Loc) + as.factor(Met) + as.factor(Periodo) + 
    Diverse + MTemp, family = binomial(link = "logit"), data = IXE.Models)
    summary(IXE.biAeae.Dredged)
    autoplot(IXE.biAeae.Dredged)


```



This chunk was used to compare the effects of different versions of rainfall in the model.
```{r Aeae Comparing Rainfalls}
  # Libraries
    library(MuMIn) # pdredge()
    library(parallel) # clusterExport()

  # Base Rain  
    IXE.biAeae.Rain <- glm(biAeae ~ as.factor(Loc) + as.factor(Mes) + as.factor(Periodo) + as.factor(Met) +
                     MTemp + MHum + Vien + Rain + Diverse, family = binomial(link = "logit"), data = IXE.Models)
    
  # Rain14DMA
    IXE.biAeae.Rain14DMA <- glm(biAeae ~ as.factor(Loc) + as.factor(Mes) + as.factor(Periodo) + as.factor(Met) +
                             MTemp + MHum + Vien + Rain14DMA + Diverse, family = binomial(link = "logit"), data = IXE.Models)

  # Rain14DSum
    IXE.biAeae.Rain14DSum <- glm(biAeae ~ as.factor(Loc) + as.factor(Mes) + as.factor(Periodo) + as.factor(Met) +
                              MTemp + MHum + Vien + Rain14DSum + Diverse, family = binomial(link = "logit"), data = IXE.Models)
    
  # Set the NA action to fail to ensure complete cases
    options(na.action = "na.fail")
  
  # Create a cluster for parallel processing
    cl <- makeCluster(detectCores() - 1)
    clusterEvalQ(cl, {
      library(MuMIn)
    })
    clusterExport(cl, list("IXE.biAeae.Rain", "IXE.biAeae.Rain14DMA", "IXE.biAeae.Rain14DSum", "IXE.Models"))
  
  # Perform the dredge operation with parallel processing for both models
    dredge.IXE.biAeae.Rain <- dredge(IXE.biAeae.Rain, cluster = cl)
    dredge.IXE.biAeae.Rain14DMA <- dredge(IXE.biAeae.Rain14DMA, cluster = cl)
    dredge.IXE.biAeae.Rain14DSum <- dredge(IXE.biAeae.Rain14DSum, cluster = cl)
  
  # Stop the cluster after dredging
    stopCluster(cl)
  
  # Reset the NA action to omit missing values
    options(na.action = "na.omit")
  
  # Summary of the best model (based on AICc by default)
    summary(get.models(dredge.IXE.biAeae.Rain, 1)[[1]])
    summary(get.models(dredge.IXE.biAeae.Rain14DMA, 1)[[1]])
    summary(get.models(dredge.IXE.biAeae.Rain14DSum, 1)[[1]])
    


```


